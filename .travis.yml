# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements. See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License. You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Spark provides this Travis CI configuration file to help contributors
# check Scala/Java style conformance and JDK7/8 compilation easily
# during their preparing pull requests.
#   - Scalastyle is executed during `maven install` implicitly.
#   - Java Checkstyle is executed by `lint-java`.
# See the related discussion here.
# https://github.com/apache/spark/pull/12980

# 1. Choose OS (Ubuntu 14.04.3 LTS Server Edition 64bit, ~2 CORE, 7.5GB RAM)
sudo: required
dist: xenial

# 2. Choose language and target JDKs for parallel builds.
language: scala
scala:
  - 2.11.8
jdk:
  - openjdk8

env:
  - MVN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=1g -Dorg.slf4j.simpleLogger.defaultLogLevel=WARN"

# 3. Setup cache directory for SBT and Maven.
cache:
  directories:
  - $HOME/.sbt
  - $HOME/.m2
  - $HOME/.ivy2

# 4. Turn off notifications.
notifications:
  email:
    on_success: always
    on_failure: always

before_install:
  - unset SBT_OPTS JVM_OPTS
  - curl -o $HOME/.m2/settings.xml https://raw.githubusercontent.com/trajano/trajano/master/src/site/resources/settings.xml
  - wget -P $HOME/.m2/repository/yaooqinn/spark-authorizer/2.1.1 http://dl.bintray.com/spark-packages/maven/yaooqinn/spark-authorizer/2.1.1/spark-authorizer-2.1.1.jar
  - wget -P $HOME/.m2/repository/yaooqinn/spark-authorizer/2.1.1 http://dl.bintray.com/spark-packages/maven/yaooqinn/spark-authorizer/2.1.1/spark-authorizer-2.1.1.pom

before_deploy:
  - ./dev/make-distribution.sh --name ne-$TRAVIS_TAG --pip --tgz -Pspark-ganglia-lgpl -Phadoop-2.7 -Dhadoop.version=2.7.3 -Phive -Phive-thriftserver -Pyarn

deploy:
  - provider: releases
    api_key: $GITHUB_TOKEN
    file_glob: true
    file: spark-2.3.2-bin-ne-$TRAVIS_TAG.tgz
    skip_cleanup: true
    on:
      tags: true

# 5. Run maven install before running lint-java.
install:
  - build/mvn --no-transfer-progress -Pspark-ganglia-lgpl -Phadoop-2.7 -Dhadoop.version=2.7.3 -Phive -Phive-thriftserver -Pyarn install -DskipTests

# 6. Run tests

matrix:
  include:
    - name: core
      env: PROFILES="" MODULES=core/test
    - name: streaming
      env: PROFILES="" MODULES=streaming/test
    - name: ml
      env: PROFILES="" MODULES=mllib/test
    - name: graphx
      env: PROFILES="" MODULES=graphx/test
    - name: network
      env: PROFILES="" MODULES=network-common/test
    - name: shuffle
      env: PROFILES="" MODULES=network-shuffle/test
    - name: unsafe
      env: PROFILES="" MODULES=unsafe/test
    - name: yarn
      env: PROFILES="-Pyarn" MODULES="yarn/test"
    - name: repl
      env: PROFILES="" MODULES=repl/test
    - name: launcher
      env: PROFILES="" MODULES=launcher/test
    - name: catalyst
      env: PROFILES="" MODULES=catalyst/test
    - name: sql-java-test
      env: PROFILES="" MODULES="sql/test"
    - name: hive
      env: PROFILES="-Phive" MODULES="hive/test"
    - name: hive-thriftserver
      env: PROFILES="-Phive -Phive-thriftserver" MODULES="hive-thriftserver/test"

script:
  - ./build/sbt -mem 4096 $PROFILES $MODULES -B -V -Dorg.slf4j.simpleLogger.defaultLogLevel=WARN

after_success:
  - echo "Travis exited with ${TRAVIS_TEST_RESULT}"

after_failure:
  - echo "Travis exited with ${TRAVIS_TEST_RESULT}"